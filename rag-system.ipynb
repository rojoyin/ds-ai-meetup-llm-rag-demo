{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG System",
   "id": "ac66544111c17d17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dependencies",
   "id": "e9713f7ce2ee4e3b"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:16.467681Z",
     "start_time": "2025-02-25T22:13:55.498043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%pip install --upgrade pip --quiet\n",
    "%pip install pandas==2.2.3 --quiet\n",
    "%pip install openai==1.62.0 --quiet\n",
    "%pip install langchain==0.3.18 --quiet\n",
    "%pip install faiss-cpu==1.10.0 --quiet\n",
    "%pip install ipywidgets==8.1.5 --quiet\n",
    "%pip install langchain-community==0.3.17 --quiet\n",
    "%pip uninstall langchain-community==0.3.17 -y --quiet\n",
    "%pip uninstall tiktoken==0.8.0 -y --quiet\n",
    "%pip install langchain-openai==0.3.6 --quiet\n",
    "%pip install python-dotenv==1.0.1 --quiet"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:16.483239Z",
     "start_time": "2025-02-25T22:14:16.474697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "30fff46ed627a4d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading the dataset into a DataFrame",
   "id": "cb8d106974d16bee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:25:01.105430Z",
     "start_time": "2025-02-25T22:25:01.097131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_dataset(file_path):\n",
    "    \"\"\"Loads the dataset from a CSV file.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df"
   ],
   "id": "c154f5aca0724ce5",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data preprocess\n",
    "1. Drop records where Title or Plot are missing (NaN)\n",
    "2. Limits the fields we want to use to Title and Plot, merging them into a single field called Content. One entry is created for each movie"
   ],
   "id": "5ae6255ae1a14821"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:16.602404Z",
     "start_time": "2025-02-25T22:14:16.588485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Prepares the dataset by extracting titles and plots.\"\"\"\n",
    "    df = df[['Title', 'Plot']].dropna()\n",
    "    df[\"Content\"] = df.apply(lambda row: f\"Title: {row['Title']}\\nPlot: {row['Plot']}\", axis=1)\n",
    "    return df"
   ],
   "id": "68fa30b28a984910",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Text chunking\n",
    "Splits long texts into chunks of fixed size. The overlap will be used to ensure that some text is repeated between consecutive chunks, this will maintain context"
   ],
   "id": "9d5bcfa50a949378"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:16.660380Z",
     "start_time": "2025-02-25T22:14:16.655771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_text_into_chunks(texts, chunk_size=500, chunk_overlap=50):\n",
    "    \"\"\"Splits the text into smaller chunks for better processing.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len\n",
    "    )\n",
    "    return text_splitter.create_documents(texts)"
   ],
   "id": "3287f197220a076b",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Helper function\n",
    "Checks if the data is already stored in embeddings, this will help us to not reprocess the data unnecessarily"
   ],
   "id": "95d029ea996dbb24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:16.713129Z",
     "start_time": "2025-02-25T22:14:16.707871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def index_exists(index_folder):\n",
    "    \"\"\"Checks if FAISS index folder exists and is not empty.\"\"\"\n",
    "    return os.path.exists(index_folder) and os.listdir(index_folder)"
   ],
   "id": "aca7821ccd007056",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Helper function to store embeddings in local folder\n",
    "Store embeddings into a folder specified by `index_folder`"
   ],
   "id": "e37e1cbb10e66538"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:16.782254Z",
     "start_time": "2025-02-25T22:14:16.768258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_and_save_faiss_index(documents, embeddings, index_folder):\n",
    "    \"\"\"Creates FAISS index and saves it locally.\"\"\"\n",
    "    vector_db = FAISS.from_documents(documents, embeddings)\n",
    "    vector_db.save_local(index_folder)\n",
    "    print(f\"FAISS index saved to {index_folder}\")"
   ],
   "id": "d81930e14dcdc1e3",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load FAISS index",
   "id": "9a52f3eb860bcf4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:16.839414Z",
     "start_time": "2025-02-25T22:14:16.832906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_faiss_index(index_folder, embeddings):\n",
    "    \"\"\"Loads FAISS index from local folder.\"\"\"\n",
    "    vector_db = FAISS.load_local(index_folder, embeddings, allow_dangerous_deserialization=True)\n",
    "    print(f\"FAISS index loaded from {index_folder}\")\n",
    "    return vector_db"
   ],
   "id": "7e9cd9d034751563",
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create the LLM model with OpenAI",
   "id": "fc52e432843e785c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:16.898458Z",
     "start_time": "2025-02-25T22:14:16.893459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_llm_model(model_name=\"gpt-3.5-turbo-0125\", temperature=0):\n",
    "    \"\"\"Initializes the OpenAI language model for text generation.\"\"\"\n",
    "    return ChatOpenAI(\n",
    "        model_name=model_name,\n",
    "        temperature=temperature\n",
    "    )"
   ],
   "id": "f61034c3c4c6ca54",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a RAG pipeline",
   "id": "d8c43b5f6e1d74d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:16.949752Z",
     "start_time": "2025-02-25T22:14:16.946259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_rag_pipeline(llm, vector_db):\n",
    "    \"\"\"Creates a Retrieval-Augmented Generation (RAG) pipeline.\"\"\"\n",
    "    retriever = vector_db.as_retriever()\n",
    "    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")"
   ],
   "id": "82aa4333f0ba282d",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function to ask movie-related questions",
   "id": "aaa978a24a9219fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:17.018245Z",
     "start_time": "2025-02-25T22:14:17.011784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ask_movie_question(qa_chain, question):\n",
    "    \"\"\"Queries the RAG pipeline with a movie-related question and a custom system prompt.\"\"\"\n",
    "    from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "    SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "    You are a movie expert with deep knowledge of film plots and cinematic history.\n",
    "    Provide detailed and accurate answers based on the movie plot data.\n",
    "    Always include the movie title in your response.\n",
    "    If you don't have actual information about the movie, reply: This movie is not in the dataset provided\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", SYSTEM_PROMPT_TEMPLATE.strip()),\n",
    "            (\"human\", \"Respond to the question: {question}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    full_prompt = prompt_template.format_messages(question=question)\n",
    "\n",
    "    response = qa_chain.invoke({\"query\": question, \"input_messages\": full_prompt})\n",
    "    return response"
   ],
   "id": "1655489070b2744f",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Connecting all together",
   "id": "ec3235640a93eaa3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:51.873093Z",
     "start_time": "2025-02-25T22:14:17.089938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    INDEX_FOLDER = \"faiss_movie_embeddings\"\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    if index_exists(INDEX_FOLDER):\n",
    "        vector_db = load_faiss_index(INDEX_FOLDER, embeddings)\n",
    "    else:\n",
    "        dataset_path = \"wiki_movie_plots_reduced.csv\"\n",
    "        df = load_dataset(dataset_path)\n",
    "        df = preprocess_data(df)\n",
    "        documents = split_text_into_chunks(df[\"Content\"].tolist())\n",
    "        create_and_save_faiss_index(documents, embeddings, INDEX_FOLDER)\n",
    "        vector_db = load_faiss_index(INDEX_FOLDER, embeddings)\n",
    "\n",
    "    # Create the LLM model and the RAG pipeline\n",
    "    llm = create_llm_model(model_name=\"gpt-3.5-turbo-0125\")\n",
    "    qa_chain = create_rag_pipeline(llm, vector_db)"
   ],
   "id": "fdfb6496650cfdd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to faiss_movie_embeddings\n",
      "FAISS index loaded from faiss_movie_embeddings\n"
     ]
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Query 1. Movie that is not part of the dataset",
   "id": "21971064c3fd5b1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:53.313879Z",
     "start_time": "2025-02-25T22:14:51.924577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    question = \"What is the plot of the movie Inception?\"\n",
    "    answer = ask_movie_question(qa_chain, question)\n",
    "    print(answer)"
   ],
   "id": "b174dcda12cd7569",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the plot of the movie Inception?', 'input_messages': [SystemMessage(content=\"You are a movie expert with deep knowledge of film plots and cinematic history.\\n    Provide detailed and accurate answers based on the movie plot data.\\n    Always include the movie title in your response.\\n    If you don't have actual information about the movie, reply: This movie is not in the dataset provided\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Respond to the question: What is the plot of the movie Inception?', additional_kwargs={}, response_metadata={})], 'result': 'I\\'m sorry, but the plot you provided is not from the movie \"Inception.\" Would you like a summary of the actual plot of \"Inception\"?'}\n"
     ]
    }
   ],
   "execution_count": 163
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Query 2. Movie that is part of the dataset",
   "id": "a18dad0437e326b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:55.296859Z",
     "start_time": "2025-02-25T22:14:53.362248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    # Example query\n",
    "    question = \"What is the plot of the movie Underworld?\"\n",
    "    answer = ask_movie_question(qa_chain, question)\n",
    "    print(answer)"
   ],
   "id": "8cb5a18d8b7248fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the plot of the movie Underworld?', 'input_messages': [SystemMessage(content=\"You are a movie expert with deep knowledge of film plots and cinematic history.\\n    Provide detailed and accurate answers based on the movie plot data.\\n    Always include the movie title in your response.\\n    If you don't have actual information about the movie, reply: This movie is not in the dataset provided\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Respond to the question: What is the plot of the movie Underworld?', additional_kwargs={}, response_metadata={})], 'result': 'The plot of \"Underworld: Blood Wars\" revolves around the remaining vampire covens being threatened by the Lycans. Both species are searching for Selene for different reasons, with the vampires seeking justice and the Lycans wanting to use her to locate Eve, whose blood can create vampire-werewolf hybrids. The story involves battles, betrayals, and Selene gaining new abilities to fight against the enemies.'}\n"
     ]
    }
   ],
   "execution_count": 164
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Query 3. Create a response, provided some context",
   "id": "da744a2d15bfd9a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:56.410425Z",
     "start_time": "2025-02-25T22:14:55.316375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    # Example query\n",
    "    question = \"What movie can you suggest me if I like vampire movies?\"\n",
    "    answer = ask_movie_question(qa_chain, question)\n",
    "    print(answer)"
   ],
   "id": "aace86156cf3c836",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What movie can you suggest me if I like vampire movies?', 'input_messages': [SystemMessage(content=\"You are a movie expert with deep knowledge of film plots and cinematic history.\\n    Provide detailed and accurate answers based on the movie plot data.\\n    Always include the movie title in your response.\\n    If you don't have actual information about the movie, reply: This movie is not in the dataset provided\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Respond to the question: What movie can you suggest me if I like vampire movies?', additional_kwargs={}, response_metadata={})], 'result': 'If you enjoy vampire movies, you might like \"Underworld: Blood Wars\" based on the plot provided. It\\'s a part of the Underworld series that focuses on the conflict between vampires and Lycans.'}\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Query 4. Create a response, provided some context (2)",
   "id": "dc2b6eddd357ea06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T22:14:57.231416Z",
     "start_time": "2025-02-25T22:14:56.455889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    # Example query\n",
    "    question = \"I hate romantic movies, what do I have to avoid?\"\n",
    "    answer = ask_movie_question(qa_chain, question)\n",
    "    print(answer)"
   ],
   "id": "eb515fc80239c1e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'I hate romantic movies, what do I have to avoid?', 'input_messages': [SystemMessage(content=\"You are a movie expert with deep knowledge of film plots and cinematic history.\\n    Provide detailed and accurate answers based on the movie plot data.\\n    Always include the movie title in your response.\\n    If you don't have actual information about the movie, reply: This movie is not in the dataset provided\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Respond to the question: I hate romantic movies, what do I have to avoid?', additional_kwargs={}, response_metadata={})], 'result': 'You should avoid \"Solo\" as it is a romantic drama movie.'}\n"
     ]
    }
   ],
   "execution_count": 166
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
